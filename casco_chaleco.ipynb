{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eOfkbc9B0r1M",
        "outputId": "b350c91d-ac39-4a18-9c9f-69e23c4fb66d"
      },
      "outputs": [],
      "source": [
        "#!pip install ultralytics roboflow opencv-python\n",
        "#pip install pyqt5 opencv-python ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQOh60aU1AgL",
        "outputId": "70ff8367-875b-407f-ea9e-c3223171e0be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "El dataset y el modelo se han descargado en: c:\\Users\\jimen\\Downloads\\proyecto1\\Safety-vest---v4-1\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "# Â¡Reemplaza esta clave con tu propia API key de Roboflow!\n",
        "# Puedes encontrar tu API key en https://app.roboflow.com/settings\n",
        "rf = Roboflow(api_key=\"HGpn9sxgRvVoq6BS6pDB\")\n",
        "\n",
        "# Â¡Reemplaza con el nombre de tu espacio de trabajo y el nombre de tu proyecto!\n",
        "workspace = rf.workspace(\"prototipo-rro16\")\n",
        "project = workspace.project(\"safety-vest---v4-he0au\")\n",
        "\n",
        "# Â¡Reemplaza con el nÃºmero de la versiÃ³n que quieres descargar y el formato (\"yolov8\")!\n",
        "# Puedes ver las versiones de tu dataset en la pÃ¡gina de tu proyecto en Roboflow\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")\n",
        "\n",
        "print(f\"El dataset y el modelo se han descargado en: {dataset.location}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmFf3DQ45302",
        "outputId": "7c0347cd-f113-4972-de7e-618712127cc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"HGpn9sxgRvVoq6BS6pDB\")\n",
        "project = rf.workspace(\"prototipo-rro16\").project(\"safety-vest---v4-he0au\")\n",
        "dataset = project.version(1).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWZ7C35d5Yh9",
        "outputId": "5c217ab6-902f-42b3-ed0f-24043a6ea9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['data.yaml', 'README.dataset.txt', 'README.roboflow.txt', 'test', 'train', 'valid']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "ruta_dataset = './Safety-vest---v4-1'  # Esto busca en la carpeta actual de tu proyecto\n",
        "print(os.listdir('C:\\\\Users\\\\jimen\\\\Downloads\\\\proyecto1\\\\Safety-vest---v4-1'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zjN_2ZYi8L0w",
        "outputId": "ae93fb63-73f1-4b46-839a-fc5239a0098a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.1.61)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n",
            "Requirement already satisfied: pillow-heif>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.22.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.57.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n"
          ]
        }
      ],
      "source": [
        "#!pip install roboflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7IVGDQW8VAP",
        "outputId": "2d125304-5b49-404f-b5fa-a7fbf00cde72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivos en train: ['images', 'labels']\n",
            "Archivos en valid: ['images', 'labels']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Update the path to your downloaded dataset folder:\n",
        "#dataset_folder = '/content/Safety-vest---v4-1'\n",
        "dataset_folder = 'C:\\\\Users\\\\jimen\\\\Downloads\\\\proyecto1\\\\Safety-vest---v4-1'\n",
        "\n",
        "# Construct the correct paths for train and valid folders:\n",
        "train_folder = os.path.join(dataset_folder, 'train')\n",
        "valid_folder = os.path.join(dataset_folder, 'valid')\n",
        "\n",
        "# Now, list the files in the correct directories:\n",
        "print(\"Archivos en train:\", os.listdir(train_folder))\n",
        "print(\"Archivos en valid:\", os.listdir(valid_folder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO1h2n8y8s5t",
        "outputId": "470a696b-11ff-4df4-d6a8-72c05aad6c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 4\n",
            "names: ['helmet', 'not_helmet', 'not_reflective', 'reflective']\n",
            "\n",
            "roboflow:\n",
            "  workspace: prototipo-rro16\n",
            "  project: safety-vest---v4-he0au\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/prototipo-rro16/safety-vest---v4-he0au/dataset/1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Assuming your dataset is downloaded to 'Safety-vest---v4-1'\n",
        "dataset_folder = 'C:\\\\Users\\\\jimen\\\\Downloads\\\\proyecto1\\\\Safety-vest---v4-1'\n",
        "# Update this path if it is different.\n",
        "\n",
        "# Construct the correct path to your data.yaml file:\n",
        "data_yaml_path = os.path.join(dataset_folder, 'data.yaml')\n",
        "\n",
        "# Now, open the file:\n",
        "with open(data_yaml_path, \"r\") as file:\n",
        "    print(file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuHhxtAR-IP-",
        "outputId": "d90ccac3-e23e-4280-b7ef-6cadb27943aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contenido de la carpeta actual: ['casco_chaleco.ipynb', 'istockphoto-1399337320-612x612.jpg', 'README.dataset.txt', 'README.roboflow.txt', 'runs', 'Safety-vest---v4-1', 'test', 'train', 'valid', 'yolov8n.pt']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"Contenido de la carpeta actual:\", os.listdir(\".\"))\n",
        "if os.path.exists(\"seguridad-1\"):\n",
        "    print(\"Contenido de seguridad-1:\", os.listdir(\"seguridad-1\"))\n",
        "    if os.path.exists(\"seguridad-1/valid\"):\n",
        "        print(\"Contenido de seguridad-1/valid:\", os.listdir(\"seguridad-1/valid\"))\n",
        "    if os.path.exists(\"seguridad-1/train\"):\n",
        "        print(\"Contenido de seguridad-1/train:\", os.listdir(\"seguridad-1/train\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_5DS4AP-R_N",
        "outputId": "50cef0e0-1b86-47ac-e9cd-4792afaa1b6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.111  Python-3.12.6 torch-2.6.0+cpu CPU (11th Gen Intel Core(TM) i5-11400H 2.70GHz)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:/Users/jimen/Downloads/proyecto1/Safety-vest---v4-1/data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train7\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 123.099.6 MB/s, size: 66.0 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\jimen\\Downloads\\proyecto1\\train\\labels.cache... 314 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 314/314 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 208.7220.2 MB/s, size: 141.5 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\jimen\\Downloads\\proyecto1\\valid\\labels.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs\\detect\\train7\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 416 train, 416 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\detect\\train7\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/5         0G      1.391      3.535      1.375         84        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:40<00:00,  2.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        468     0.0199      0.795     0.0805     0.0445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        2/5         0G      1.234      2.024      1.124         91        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:46<00:00,  2.31s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        468      0.564      0.249      0.431      0.275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        3/5         0G      1.163      1.497       1.09         88        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:46<00:00,  2.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        468      0.528      0.491      0.497      0.314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        4/5         0G      1.102      1.317      1.085         75        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:45<00:00,  2.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        468      0.582      0.517      0.588      0.405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        5/5         0G      1.077      1.233      1.069        111        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:45<00:00,  2.30s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        468       0.67      0.699      0.709       0.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "5 epochs completed in 0.071 hours.\n",
            "Optimizer stripped from runs\\detect\\train7\\weights\\last.pt, 6.2MB\n",
            "Optimizer stripped from runs\\detect\\train7\\weights\\best.pt, 6.2MB\n",
            "\n",
            "Validating runs\\detect\\train7\\weights\\best.pt...\n",
            "Ultralytics 8.3.111  Python-3.12.6 torch-2.6.0+cpu CPU (11th Gen Intel Core(TM) i5-11400H 2.70GHz)\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        468       0.67        0.7      0.709       0.47\n",
            "                helmet         68        167      0.862       0.82      0.881      0.654\n",
            "            not_helmet         33         70      0.525      0.543      0.547      0.372\n",
            "        not_reflective         79        196      0.717      0.867      0.821      0.497\n",
            "            reflective         19         35      0.577      0.571      0.588      0.357\n",
            "Speed: 0.9ms preprocess, 37.4ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns\\detect\\train7\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#from ultralytics import YOLO\n",
        "\n",
        "#model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Update the data path to the correct location of your data.yaml file\n",
        "# Replace with the actual path to your data.yaml file:\n",
        "#data_yaml_path = '/content/Safety-vest---v4-1/data.yaml'\n",
        "#data_yaml_path = 'C:\\\\Users\\\\jimen\\\\Downloads\\\\proyecto1\\\\Safety-vest---v4-1'\n",
        "#results = model.train(data=data_yaml_path, epochs=30, imgsz=416)\n",
        "\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Ruta correcta apuntando al archivo data.yaml, no a la carpeta\n",
        "data_yaml_path = 'C:/Users/jimen/Downloads/proyecto1/Safety-vest---v4-1/data.yaml'\n",
        "\n",
        "# Entrenamiento\n",
        "results = model.train(data=data_yaml_path, epochs=5, imgsz=416)\n",
        "#results = model.train(data=data_yaml_path, epochs=30, imgsz=416)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ZzQdhVDjErdn",
        "outputId": "2d3e7244-e3b2-49c3-dfcc-c1cc7607fb0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 C:\\Users\\jimen\\Downloads\\proyecto1\\istockphoto-1399337320-612x612.jpg: 288x416 2 helmets, 2 reflectives, 99.1ms\n",
            "Speed: 2.3ms preprocess, 99.1ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 416)\n",
            "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "#results = model.predict(\"C:\\Users\\jimen\\Downloads\\proyecto1\\istockphoto-1399337320-612x612.jpg\", save=True)\n",
        "#results = model.predict(\"C:/Users/jimen/Downloads/proyecto1/istockphoto-1399337320-612x612.jpg\", save=True)\n",
        "\n",
        "\n",
        "model = YOLO(\"C:/Users/jimen/Downloads/proyecto1/runs/detect/train6/weights/best.pt\")\n",
        "results = model.predict(r\"C:\\Users\\jimen\\Downloads\\proyecto1\\istockphoto-1399337320-612x612.jpg\", save=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 C:\\Users\\jimen\\Downloads\\proyecto1\\reactiva-la-construccion.png: 288x416 3 helmets, 2 reflectives, 96.7ms\n",
            "Speed: 3.0ms preprocess, 96.7ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 416)\n",
            "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#CARGA SOLO ESTO PARA QUE EL MODELO CARGUE NUEVAS IMAGENES SIN NECESIDAD DE ENTRENAR EL MODELO DE NUEVO\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# r antes de la cadena para evitar errores de escape\n",
        "model = YOLO(r\"C:\\Users\\jimen\\Downloads\\proyecto1\\runs\\detect\\train6\\weights\\best.pt\")\n",
        "results = model.predict(r\"C:\\Users\\jimen\\Downloads\\proyecto1\\reactiva-la-construccion.png\", save=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:/Users/jimen/Downloads/proyecto1/runs\\detect\\train5\\weights\\best.pt\n",
            "C:/Users/jimen/Downloads/proyecto1/runs\\detect\\train5\\weights\\last.pt\n",
            "C:/Users/jimen/Downloads/proyecto1/runs\\detect\\train6\\weights\\best.pt\n",
            "C:/Users/jimen/Downloads/proyecto1/runs\\detect\\train6\\weights\\last.pt\n"
          ]
        }
      ],
      "source": [
        "#para listar las rutas\n",
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(\"C:/Users/jimen/Downloads/proyecto1/runs\"):\n",
        "    for file in files:\n",
        "        if file.endswith(\".pt\"):\n",
        "            print(os.path.join(root, file))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "APLICACION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#CON ALERTAS POR FALTA DE EQUIPO DE SEGURIDAD, SE SALE DEL PROGRAMA CON Q\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "\n",
        "# Cargar tu modelo YOLO entrenado\n",
        "model = YOLO(\"C:/Users/jimen/Downloads/proyecto1/runs/detect/train6/weights/best.pt\")\n",
        "\n",
        "# Lista de tus videos locales\n",
        "video_paths = [\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\CONSTRUCCIONES BUENVIVIR - VIDEO CORPORATIVO.mp4\",\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\Curso de Seguridad en la construcciÃ³n.mp4\",\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\VIDEO DE SEGURIDAD.mp4\",\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\videoplayback.mp4\"\n",
        "]\n",
        "\n",
        "# Abre cada video\n",
        "caps = [cv2.VideoCapture(path) for path in video_paths]\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "while True:\n",
        "    frames = []\n",
        "    for idx, cap in enumerate(caps):\n",
        "        ret, frame = cap.read()\n",
        "        alert_text = \"\"\n",
        "\n",
        "        if not ret:\n",
        "            # Pantalla negra cuando el video termina o falla\n",
        "            frame = np.zeros((256, 416, 3), dtype=np.uint8)\n",
        "            alert_text = \"CAM DESCONECTADA\"\n",
        "        else:\n",
        "            # PredicciÃ³n\n",
        "            results = model.predict(source=frame, save=False, show=False, conf=0.3)\n",
        "            names = results[0].names\n",
        "            detected = [names[int(cls)] for cls in results[0].boxes.cls.cpu().numpy()]\n",
        "\n",
        "            # Verifica si falta casco o chaleco\n",
        "            if \"helmet\" not in detected or \"reflective\" not in detected:\n",
        "                alert_text = \"ALERTA: Falta Equipo de Seguridad\"\n",
        "            frame = results[0].plot()\n",
        "\n",
        "        # Redimensiona para la cuadrÃ­cula\n",
        "        frame = cv2.resize(frame, (416, 256))\n",
        "\n",
        "        # Etiqueta \"CAM X\"\n",
        "        cam_label = f\"CAM {idx+1}\"\n",
        "        cv2.putText(frame, cam_label, (10, 25), font, 0.8, (0, 0, 255), 2)\n",
        "\n",
        "        # Si hay alerta, mostrar texto en rojo\n",
        "        if alert_text:\n",
        "            cv2.putText(frame, alert_text, (10, 245), font, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "        frames.append(frame)\n",
        "\n",
        "    # Completa 4 cÃ¡maras si falta alguna\n",
        "    while len(frames) < 4:\n",
        "        black = np.zeros((256, 416, 3), dtype=np.uint8)\n",
        "        cv2.putText(black, \"CAM DESCONECTADA\", (10, 245), font, 0.7, (0, 0, 255), 2)\n",
        "        frames.append(black)\n",
        "\n",
        "    # Crear cuadrÃ­cula 2x2\n",
        "    top = np.hstack((frames[0], frames[1]))\n",
        "    bottom = np.hstack((frames[2], frames[3]))\n",
        "    grid = np.vstack((top, bottom))\n",
        "\n",
        "    # Marco negro estilo CCTV\n",
        "    grid = cv2.copyMakeBorder(grid, 20, 20, 20, 20, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
        "\n",
        "    # Timestamp global\n",
        "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    cv2.putText(grid, f'CCTV Centro Seguridad | {timestamp}', (30, 30), font, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "    # Mostrar en ventana\n",
        "    cv2.imshow('ðŸ›¡ï¸ CCTV - Centro de Monitoreo 4 CÃ¡maras', grid)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Liberar recursos\n",
        "for cap in caps:\n",
        "    cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.111  Python-3.12.6 torch-2.6.0+cpu CPU (11th Gen Intel Core(TM) i5-11400H 2.70GHz)\n",
            "Ultralytics 8.3.111  Python-3.12.6 torch-2.6.0+cpu CPU (11th Gen Intel Core(TM) i5-11400H 2.70GHz)\n",
            "Ultralytics 8.3.111  Python-3.12.6 torch-2.6.0+cpu CPU (11th Gen Intel Core(TM) i5-11400H 2.70GHz)\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "#muestra las alertas\n",
        "import cv2\n",
        "import threading\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "from PIL import Image, ImageTk\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Carga el modelo ya entrenado\n",
        "model = YOLO(\"C:/Users/jimen/Downloads/proyecto1/runs/detect/train6/weights/best.pt\")\n",
        "\n",
        "# Rutas de tus videos\n",
        "videos = [\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\CONSTRUCCIONES BUENVIVIR - VIDEO CORPORATIVO.mp4\",\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\Curso de Seguridad en la construcciÃ³n.mp4\",\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\VIDEO DE SEGURIDAD.mp4\",\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\videoplayback.mp4\"\n",
        "]\n",
        "\n",
        "# Contador de alertas por cÃ¡mara\n",
        "alert_count = {f\"Cam {i+1}\": 0 for i in range(len(videos))}\n",
        "\n",
        "# Crear la ventana\n",
        "root = tk.Tk()\n",
        "root.title(\"ðŸ›¡ï¸ Centro de Monitoreo - CCTV Seguridad\")\n",
        "root.geometry(\"1280x800\")  # ventana amplia\n",
        "\n",
        "# Divide la ventana en dos frames: cÃ¡maras arriba, historial abajo\n",
        "main_frame = tk.PanedWindow(root, orient=tk.VERTICAL)\n",
        "main_frame.pack(fill=tk.BOTH, expand=True)\n",
        "\n",
        "# Frame para las cÃ¡maras\n",
        "cams_frame = tk.Frame(main_frame, bg=\"gray\")\n",
        "main_frame.add(cams_frame, stretch='always')\n",
        "\n",
        "# Frame para historial\n",
        "history_frame = tk.Frame(main_frame, bg=\"black\", height=200)\n",
        "main_frame.add(history_frame)\n",
        "\n",
        "# Configurar las cÃ¡maras en 2x2\n",
        "labels = []\n",
        "for i in range(4):\n",
        "    frame = tk.Frame(cams_frame, bd=2, relief=tk.RIDGE)\n",
        "    frame.grid(row=i//2, column=i%2, padx=5, pady=5, sticky=\"nsew\")\n",
        "    label = tk.Label(frame)\n",
        "    label.pack(expand=True, fill='both')\n",
        "    labels.append(label)\n",
        "\n",
        "# Que las celdas se expandan correctamente\n",
        "cams_frame.grid_rowconfigure(0, weight=1)\n",
        "cams_frame.grid_rowconfigure(1, weight=1)\n",
        "cams_frame.grid_columnconfigure(0, weight=1)\n",
        "cams_frame.grid_columnconfigure(1, weight=1)\n",
        "\n",
        "# Historial de alertas con scroll\n",
        "history_label = tk.Label(history_frame, text=\"ðŸ“‹ Historial de Alertas:\", anchor=\"w\", fg=\"lime\", bg=\"black\", font=(\"Arial\", 12, \"bold\"))\n",
        "history_label.pack(fill='x')\n",
        "\n",
        "history_text = tk.Text(history_frame, bg=\"black\", fg=\"lime\", font=(\"Consolas\", 10), height=10)\n",
        "history_text.pack(side='left', fill='both', expand=True)\n",
        "\n",
        "scrollbar = ttk.Scrollbar(history_frame, command=history_text.yview)\n",
        "scrollbar.pack(side='right', fill='y')\n",
        "history_text.config(yscrollcommand=scrollbar.set)\n",
        "\n",
        "# FunciÃ³n para registrar alertas\n",
        "def log_alert(camera):\n",
        "    alert_count[camera] += 1\n",
        "    history_text.config(state='normal')\n",
        "    history_text.insert('end', f\"âš ï¸ {camera}: Falta de elementos de seguridad detectada.\\n\")\n",
        "    history_text.see('end')\n",
        "    history_text.config(state='disabled')\n",
        "\n",
        "# Procesar cada video\n",
        "def process_video(idx, video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "            continue\n",
        "\n",
        "        results = model.predict(source=frame, conf=0.4, imgsz=416, verbose=False)\n",
        "\n",
        "        for r in results:\n",
        "            names = r.names\n",
        "            for c in r.boxes.cls:\n",
        "                label = names[int(c)]\n",
        "                if label == \"not_reflective\":\n",
        "                    log_alert(f\"Cam {idx+1}\")\n",
        "\n",
        "        annotated_frame = results[0].plot()\n",
        "        rgb_image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
        "        img = ImageTk.PhotoImage(Image.fromarray(rgb_image))\n",
        "\n",
        "        labels[idx].config(image=img)\n",
        "        labels[idx].image = img\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# Lanzar hilos para cada video\n",
        "for i, path in enumerate(videos):\n",
        "    threading.Thread(target=process_video, args=(i, path), daemon=True).start()\n",
        "\n",
        "root.mainloop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#puede ser final\n",
        "import cv2\n",
        "import threading\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "from PIL import Image, ImageTk\n",
        "from ultralytics import YOLO\n",
        "from datetime import datetime\n",
        "\n",
        "# Carga el modelo entrenado\n",
        "model = YOLO(\"C:/Users/jimen/Downloads/proyecto1/runs/detect/train6/weights/best.pt\")\n",
        "\n",
        "# Rutas de los videos\n",
        "videos = [\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\CONSTRUCCIONES BUENVIVIR - VIDEO CORPORATIVO.mp4\",\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\Curso de Seguridad en la construcciÃ³n.mp4\",\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\VIDEO DE SEGURIDAD.mp4\",\n",
        "    r\"C:\\Users\\jimen\\Downloads\\proyecto1\\videoplayback.mp4\"\n",
        "]\n",
        "\n",
        "# Contador de alertas\n",
        "alert_count = {f\"CAM {i+1}\": 0 for i in range(len(videos))}\n",
        "\n",
        "# Configurar ventana principal\n",
        "root = tk.Tk()\n",
        "root.title(\"ðŸ›¡ï¸ Centro de Monitoreo - CCTV Seguridad\")\n",
        "root.geometry(\"1280x800\")\n",
        "\n",
        "# Dividir ventana\n",
        "main_frame = tk.PanedWindow(root, orient=tk.VERTICAL)\n",
        "main_frame.pack(fill=tk.BOTH, expand=True)\n",
        "\n",
        "# Frame para cÃ¡maras\n",
        "cams_frame = tk.Frame(main_frame, bg=\"gray\")\n",
        "main_frame.add(cams_frame, stretch='always')\n",
        "\n",
        "# Frame para historial y ranking\n",
        "bottom_frame = tk.Frame(main_frame, bg=\"black\", height=200)\n",
        "main_frame.add(bottom_frame)\n",
        "\n",
        "# Subdividir historial y ranking\n",
        "history_frame = tk.Frame(bottom_frame, bg=\"black\")\n",
        "ranking_frame = tk.Frame(bottom_frame, bg=\"black\", width=200)\n",
        "history_frame.pack(side='left', fill='both', expand=True)\n",
        "ranking_frame.pack(side='right', fill='y')\n",
        "\n",
        "# Configurar cÃ¡maras en 2x2\n",
        "labels = []\n",
        "name_labels = []\n",
        "for i in range(4):\n",
        "    frame = tk.Frame(cams_frame, bd=2, relief=tk.RIDGE)\n",
        "    frame.grid(row=i//2, column=i%2, padx=5, pady=5, sticky=\"nsew\")\n",
        "\n",
        "    name = tk.Label(frame, text=f\"CAM {i+1}\", bg=\"black\", fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
        "    name.pack(fill='x')\n",
        "    name_labels.append(name)\n",
        "\n",
        "    label = tk.Label(frame)\n",
        "    label.pack(expand=True, fill='both')\n",
        "    labels.append(label)\n",
        "\n",
        "# Que las celdas se expandan correctamente\n",
        "for i in range(2):\n",
        "    cams_frame.grid_rowconfigure(i, weight=1)\n",
        "    cams_frame.grid_columnconfigure(i, weight=1)\n",
        "\n",
        "# Historial\n",
        "history_label = tk.Label(history_frame, text=\"ðŸ“‹ Historial de Alertas:\", anchor=\"w\", fg=\"lime\", bg=\"black\", font=(\"Arial\", 12, \"bold\"))\n",
        "history_label.pack(fill='x')\n",
        "\n",
        "history_text = tk.Text(history_frame, bg=\"black\", fg=\"lime\", font=(\"Consolas\", 10), height=10)\n",
        "history_text.pack(side='left', fill='both', expand=True)\n",
        "\n",
        "scrollbar = ttk.Scrollbar(history_frame, command=history_text.yview)\n",
        "scrollbar.pack(side='right', fill='y')\n",
        "history_text.config(yscrollcommand=scrollbar.set, state='disabled')\n",
        "\n",
        "# Ranking de alertas\n",
        "ranking_label = tk.Label(ranking_frame, text=\"ðŸ† Ranking:\", anchor=\"center\", fg=\"orange\", bg=\"black\", font=(\"Arial\", 12, \"bold\"))\n",
        "ranking_label.pack(fill='x')\n",
        "ranking_text = tk.Label(ranking_frame, justify='left', bg=\"black\", fg=\"orange\", font=(\"Consolas\", 10))\n",
        "ranking_text.pack(fill='both', expand=True)\n",
        "\n",
        "# FunciÃ³n para registrar alertas\n",
        "def log_alert(camera):\n",
        "    alert_count[camera] += 1\n",
        "    now = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
        "    history_text.config(state='normal')\n",
        "    history_text.insert('end', f\"âš ï¸ {now} {camera}: Falta de elementos de seguridad detectada.\\n\")\n",
        "    history_text.see('end')\n",
        "    history_text.config(state='disabled')\n",
        "    update_ranking()\n",
        "\n",
        "# Actualizar ranking\n",
        "def update_ranking():\n",
        "    sorted_cams = sorted(alert_count.items(), key=lambda x: x[1], reverse=True)\n",
        "    text = \"\"\n",
        "    for cam, count in sorted_cams:\n",
        "        text += f\"{cam}: {count} alertas\\n\"\n",
        "    ranking_text.config(text=text)\n",
        "\n",
        "# Procesar cada video\n",
        "def process_video(idx, video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "            continue\n",
        "\n",
        "        results = model.predict(source=frame, conf=0.4, imgsz=416, verbose=False)\n",
        "        for r in results:\n",
        "            names = r.names\n",
        "            for c in r.boxes.cls:\n",
        "                label = names[int(c)]\n",
        "                if label == \"not_reflective\":\n",
        "                    log_alert(f\"CAM {idx+1}\")\n",
        "\n",
        "        annotated_frame = results[0].plot()\n",
        "        rgb_image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
        "        img = ImageTk.PhotoImage(Image.fromarray(rgb_image))\n",
        "\n",
        "        labels[idx].config(image=img)\n",
        "        labels[idx].image = img\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# Lanzar hilos para cada video\n",
        "for i, path in enumerate(videos):\n",
        "    threading.Thread(target=process_video, args=(i, path), daemon=True).start()\n",
        "\n",
        "root.mainloop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#solo camara de pc\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from datetime import datetime\n",
        "\n",
        "# Carga tu modelo entrenado\n",
        "model = YOLO(\"C:/Users/jimen/Downloads/proyecto1/runs/detect/train6/weights/best.pt\")\n",
        "\n",
        "# Intenta abrir la cÃ¡mara principal\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Verifica si se abriÃ³ correctamente\n",
        "if not cap.isOpened():\n",
        "    print(\"No se pudo acceder a la cÃ¡mara.\")\n",
        "    exit()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"No se recibiÃ³ frame desde la cÃ¡mara.\")\n",
        "        break\n",
        "\n",
        "    # PredicciÃ³n YOLOv8\n",
        "    results = model.predict(source=frame, save=False, imgsz=416, conf=0.4, verbose=False)\n",
        "    annotated_frame = results[0].plot()  # Dibujar resultados sobre el frame\n",
        "\n",
        "    # Fecha y hora\n",
        "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    cv2.putText(annotated_frame, now, (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "    # Mostrar ventana\n",
        "    cv2.imshow(\"Vista de la CÃ¡mara\", annotated_frame)\n",
        "\n",
        "    # Salir con ESC\n",
        "    if cv2.waitKey(1) & 0xFF == 27:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "SystemExit",
          "evalue": "0",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jimen\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3675: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "#interfaz 2*2\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from PyQt5.QtWidgets import QApplication, QLabel, QWidget, QGridLayout, QVBoxLayout\n",
        "from PyQt5.QtCore import QTimer, Qt\n",
        "from PyQt5.QtGui import QImage, QPixmap, QFont\n",
        "from ultralytics import YOLO\n",
        "from PyQt5.QtWidgets import QSizePolicy\n",
        "\n",
        "class CameraWidget(QWidget):\n",
        "    def __init__(self, title, camera_index=None, model=None):\n",
        "        super().__init__()\n",
        "        self.title = title\n",
        "        self.camera_index = camera_index\n",
        "        self.model = model\n",
        "        self.cap = cv2.VideoCapture(camera_index) if camera_index is not None else None\n",
        "\n",
        "        self.label = QLabel()\n",
        "        self.label.setStyleSheet(\"background-color: black; color: white;\")\n",
        "        self.label.setAlignment(Qt.AlignCenter)\n",
        "        self.label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n",
        "        self.label.setScaledContents(True)\n",
        "\n",
        "        self.titleLabel = QLabel(self.title)\n",
        "        self.titleLabel.setAlignment(Qt.AlignCenter)\n",
        "        self.titleLabel.setFont(QFont(\"Arial\", 12, QFont.Bold))\n",
        "        self.titleLabel.setStyleSheet(\"color: white;\")\n",
        "\n",
        "        layout = QVBoxLayout()\n",
        "        layout.addWidget(self.titleLabel)\n",
        "        layout.addWidget(self.label)\n",
        "        self.setLayout(layout)\n",
        "\n",
        "        if self.cap and self.cap.isOpened():\n",
        "            self.timer = QTimer()\n",
        "            self.timer.timeout.connect(self.update_frame)\n",
        "            self.timer.start(30)\n",
        "        else:\n",
        "            self.show_no_signal()\n",
        "\n",
        "    def update_frame(self):\n",
        "        ret, frame = self.cap.read()\n",
        "        if not ret:\n",
        "            self.show_no_signal()\n",
        "            return\n",
        "\n",
        "        results = self.model.predict(source=frame, imgsz=416, conf=0.4, verbose=False)\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        cv2.putText(annotated_frame, timestamp, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
        "\n",
        "        rgb_image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
        "        h, w, ch = rgb_image.shape\n",
        "        bytes_per_line = ch * w\n",
        "        qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
        "        self.label.setPixmap(QPixmap.fromImage(qt_image))\n",
        "\n",
        "    def show_no_signal(self):\n",
        "        self.label.setText(\"SIN SEÃ‘AL\")\n",
        "        self.label.setStyleSheet(\"background-color: #222; color: #FF4444; font-size: 22px;\")\n",
        "\n",
        "class MainWindow(QWidget):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.setWindowTitle(\"Sistema de Vigilancia\")\n",
        "        self.setStyleSheet(\"background-color: #333; color: white;\")\n",
        "        self.layout = QGridLayout()\n",
        "        self.setLayout(self.layout)\n",
        "\n",
        "        model_path = \"C:/Users/jimen/Downloads/proyecto1/runs/detect/train6/weights/best.pt\"\n",
        "        self.model = YOLO(model_path)\n",
        "\n",
        "        cameras = [\n",
        "            (\"Cam 1 - Ãrea de Acceso y Control\", 0),\n",
        "            (\"Cam 2 - Ãrea de Almacenamiento\", None),\n",
        "            (\"Cam 3 - Ãrea de mezcla de concreto\", None),\n",
        "            (\"Cam 4 - Ãrea de armado de acero\", None)\n",
        "        ]\n",
        "\n",
        "        positions = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
        "        for pos, (name, index) in zip(positions, cameras):\n",
        "            cam_widget = CameraWidget(name, index, self.model)\n",
        "            self.layout.addWidget(cam_widget, *pos)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app = QApplication(sys.argv)\n",
        "    window = MainWindow()\n",
        "    window.showMaximized()  # Abre maximizado\n",
        "    sys.exit(app.exec_())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
